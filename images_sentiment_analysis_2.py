# -*- coding: utf-8 -*-
"""images_sentiment_analysis-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1El83EFH3X3bCdvV1pRYGkKh8BJqocIo8

## Read Data
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.utils import to_categorical

# Load the dataset
file_path = file_path = '/content/fer2013.csv'
data = pd.read_csv(file_path)

print("\nDataset Info:")
print(data.info())

print("\nMissing Values:")
print(data.isnull().sum())

# Map emotion labels to their respective names (based on FER2013)
emotion_mapping = {
    0: "Angry",
    1: "Disgust",
    2: "Fear",
    3: "Happy",
    4: "Sad",
    5: "Surprise",
    6: "Neutral"
}

# Preprocessing: Convert pixel strings to numpy arrays
def preprocess_pixels(pixel_string):
    pixel_array = np.array([int(pixel) for pixel in pixel_string.split()])
    return pixel_array.reshape(48, 48, 1)  # Reshape to 48x48 grayscale image

print(data.columns)

print(data.head())

# Load the dataset and assign column names
column_names = ["emotion", "pixels", "Usage"]  # FER2013 has these 3 columns
data = pd.read_csv(file_path, names=column_names, skiprows=1)  # Skip the first row if it contains column headers

# Split the data based on Usage column
train_data = data[data["Usage"] == "Training"]
val_data = data[data["Usage"] == "PublicTest"]
test_data = data[data["Usage"] == "PrivateTest"]

def preprocess_pixels(pixel_string):
    pixel_array = np.array([int(pixel) for pixel in pixel_string.split()])
    return pixel_array.reshape(48, 48, 1)  # Reshape to 48x48 grayscale image

# Preprocessing: Convert pixel strings to numpy arrays
def preprocess_pixels(pixel_string):
    pixel_array = np.array([int(pixel) for pixel in pixel_string.split()])
    if pixel_array.size != 2304:  # Validate pixel data size
        raise ValueError(f"Unexpected pixel data size: {pixel_array.size}")
    return pixel_array.reshape(48, 48, 1)  # Reshape to 48x48 grayscale image

# Check for invalid pixel data sizes
valid_pixel_data = data["pixels"].apply(lambda x: len(x.split()) == 2304)
invalid_rows = data[~valid_pixel_data]

if not invalid_rows.empty:
    print("\nInvalid rows with incorrect pixel data sizes:")
    print(invalid_rows)
    # Drop invalid rows (or handle them as needed)
    data = data[valid_pixel_data]

# Apply preprocessing to the dataset
data["pixels"] = data["pixels"].apply(preprocess_pixels)

data["pixels"] = data["pixels"].apply(lambda x: x / 255.0)

# Prepare features and labels for each set
X_train = np.array([x for x in train_data["pixels"].values])  # Already reshaped by preprocess_pixels
X_val = np.array([x for x in val_data["pixels"].values])
X_test = np.array([x for x in test_data["pixels"].values])

y_train = to_categorical(train_data["emotion"].values, num_classes=7)
y_val = to_categorical(val_data["emotion"].values, num_classes=7)
y_test = to_categorical(test_data["emotion"].values, num_classes=7)

print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of first image in X_train: {X_train[0].shape}")

print("Training set shape:", X_train.shape, y_train.shape)
print("Validation set shape:", X_val.shape, y_val.shape)
print("Test set shape:", X_test.shape, y_test.shape)

print(data["pixels"].head())

print(type(X_train[0]))
print(X_train[0].shape if isinstance(X_train[0], np.ndarray) else X_train[0])

"""#FINAL"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Load the dataset
file_path = '/content/fer2013.csv'
data = pd.read_csv(file_path)

# Map emotion labels to their respective names (based on FER2013)
emotion_mapping = {
    0: "Angry",
    1: "Disgust",
    2: "Fear",
    3: "Happy",
    4: "Sad",
    5: "Surprise",
    6: "Neutral"
}

# Load the dataset and assign column names
column_names = ["emotion", "pixels", "Usage"]  # FER2013 has these 3 columns
data = pd.read_csv(file_path, names=column_names, skiprows=1)  # Skip the first row if it contains column headers

# Preprocessing: Convert pixel strings to numpy arrays
def preprocess_pixels(pixel_string):
    pixel_array = np.array([int(pixel) for pixel in pixel_string.split()])
    if pixel_array.size != 2304:  # Validate pixel data size
        raise ValueError(f"Unexpected pixel data size: {pixel_array.size}")
    return pixel_array.reshape(48, 48, 1)  # Reshape to 48x48 grayscale image

# Apply preprocessing to the dataset
data["pixels"] = data["pixels"].apply(preprocess_pixels)

# Normalize pixel values to the range [0, 1]
data["pixels"] = data["pixels"].apply(lambda x: x / 255.0)

# Split the data based on Usage column
train_data = data[data["Usage"] == "Training"]
val_data = data[data["Usage"] == "PublicTest"]
test_data = data[data["Usage"] == "PrivateTest"]

# Prepare features and labels for each set
X_train = np.stack(train_data["pixels"].values)  # Stack arrays into a single NumPy array
X_val = np.stack(val_data["pixels"].values)
X_test = np.stack(test_data["pixels"].values)

y_train = to_categorical(train_data["emotion"].values, num_classes=7)
y_val = to_categorical(val_data["emotion"].values, num_classes=7)
y_test = to_categorical(test_data["emotion"].values, num_classes=7)

# Print dataset shapes
print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of X_val: {X_val.shape}")
print(f"Shape of X_test: {X_test.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of y_val: {y_val.shape}")
print(f"Shape of y_test: {y_test.shape}")

# Display a sample image and its label
plt.imshow(X_train[0].reshape(48, 48), cmap="gray")
plt.title(f"Emotion: {emotion_mapping[np.argmax(y_train[0])]} ")
plt.axis("off")
plt.show()

# Display multiple images with their labels
num_images = 9  # Number of images to display
plt.figure(figsize=(10, 10))  # Set the figure size

for i in range(num_images):
    plt.subplot(3, 3, i + 1)  # Create a 3x3 grid
    plt.imshow(X_train[i].reshape(48, 48), cmap="gray")  # Display image
    plt.title(f"Emotion: {emotion_mapping[np.argmax(y_train[i])]}")  # Title with emotion label
    plt.axis("off")  # Turn off axes

plt.tight_layout()  # Adjust spacing between plots
plt.show()

# Plot emotion distribution
emotion_counts = data['emotion'].value_counts().sort_index()  # Count occurrences of each emotion
plt.figure(figsize=(10, 6))
plt.bar(emotion_mapping.values(), emotion_counts, color='skyblue')
plt.xlabel("Emotion")
plt.ylabel("Number of Images")
plt.title("Distribution of Emotions in the Dataset")
plt.xticks(rotation=45)
plt.show()

# Flatten all pixel values and plot the histogram
all_pixels = np.concatenate([x.flatten() for x in data["pixels"]])
plt.figure(figsize=(10, 6))
plt.hist(all_pixels, bins=50, color='gray', alpha=0.7)
plt.xlabel("Pixel Intensity")
plt.ylabel("Frequency")
plt.title("Pixel Intensity Distribution")
plt.show()

# Display sample images for each emotion
plt.figure(figsize=(15, 10))
for emotion, emotion_name in emotion_mapping.items():
    sample_image = data[data['emotion'] == emotion].iloc[0]["pixels"]  # Get first image of the emotion
    plt.subplot(2, 4, emotion + 1)  # Arrange in a 2x4 grid
    plt.imshow(sample_image.reshape(48, 48), cmap="gray")
    plt.title(emotion_name)
    plt.axis("off")

plt.tight_layout()
plt.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data augmentation example
datagen = ImageDataGenerator(
    rotation_range=30,  # Rotate the image by up to 30 degrees
    width_shift_range=0.2,  # Shift the image horizontally
    height_shift_range=0.2,  # Shift the image vertically
    zoom_range=0.2,  # Zoom in/out by up to 20%
    horizontal_flip=True  # Flip images horizontally
)

# Take a sample image
sample_image = X_train[0].reshape(1, 48, 48, 1)

# Generate augmented images
plt.figure(figsize=(12, 6))
for i, augmented_image in enumerate(datagen.flow(sample_image, batch_size=1)):
    if i == 6:  # Show 6 augmented images
        break
    plt.subplot(2, 3, i + 1)
    plt.imshow(augmented_image[0].reshape(48, 48), cmap="gray")
    plt.axis("off")

plt.tight_layout()
plt.show()

# Distribution of emotions per data split
train_counts = train_data['emotion'].value_counts().sort_index()
val_counts = val_data['emotion'].value_counts().sort_index()
test_counts = test_data['emotion'].value_counts().sort_index()

x = emotion_mapping.values()
plt.figure(figsize=(12, 6))
plt.bar(x, train_counts, color='blue', alpha=0.6, label="Training Set")
plt.bar(x, val_counts, color='orange', alpha=0.6, label="Validation Set", bottom=train_counts)
plt.bar(x, test_counts, color='green', alpha=0.6, label="Test Set", bottom=train_counts + val_counts)
plt.xlabel("Emotion")
plt.ylabel("Number of Images")
plt.title("Emotion Distribution Across Data Splits")
plt.legend()
plt.show()

# Import necessary libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Define the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(7, activation='softmax')  # 7 classes for emotions
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,  # Adjust the number of epochs as needed
    batch_size=64,  # Adjust the batch size as needed
    verbose=1
)

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Predict on the test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Get predicted class labels
y_true = np.argmax(y_test, axis=1)  # Get true class labels

# Find indices of misclassified images
misclassified_indices = np.where(y_pred_classes != y_true)[0]

# Display some misclassified images
plt.figure(figsize=(15, 10))
for i, idx in enumerate(misclassified_indices[:9]):  # Show first 9 misclassified images
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx].reshape(48, 48), cmap="gray")
    plt.title(f"True: {emotion_mapping[y_true[idx]]}\nPred: {emotion_mapping[y_pred_classes[idx]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()

# Save the entire model to an HDF5 file
model.save("emotion_detection_model.h5")

# To load the model later
from tensorflow.keras.models import load_model
loaded_model = load_model("emotion_detection_model.h5")

# Confirm the model architecture and weights are intact
model.summary()

from tensorflow.keras.models import load_model

# Load the previously saved model
model = load_model("emotion_detection_model.h5")

model.compile(optimizer='adam',  # Or your original optimizer
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Continue training for 30 more epochs
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,  # Additional epochs
    batch_size=64,
    verbose=1
)

# Evaluate the updated model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Save the updated model
model.save("updated_emotion_detection_model.h5")

# Display some misclassified images
plt.figure(figsize=(15, 10))
for i, idx in enumerate(misclassified_indices[:9]):  # Show first 9 misclassified images
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx].reshape(48, 48), cmap="gray")
    plt.title(f"True: {emotion_mapping[y_true[idx]]}\nPred: {emotion_mapping[y_pred_classes[idx]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()

# Save the entire model to an HDF5 file
model.save("update_emotion_detection_model.h5")

from tensorflow.keras.models import load_model

# Load the previously saved model
model = load_model("update_emotion_detection_model.h5")

model.compile(optimizer='adam',  # Or your original optimizer
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Continue training for 30 more epochs
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,  # Additional epochs
    batch_size=64,
    verbose=1
)

# Evaluate the updated model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Save the updated model
model.save("update2_emotion_detection_model.h5")

# Display some misclassified images
plt.figure(figsize=(15, 10))
for i, idx in enumerate(misclassified_indices[:9]):  # Show first 9 misclassified images
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx].reshape(48, 48), cmap="gray")
    plt.title(f"True: {emotion_mapping[y_true[idx]]}\nPred: {emotion_mapping[y_pred_classes[idx]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()

from tensorflow.keras.models import load_model

# Load the previously saved model
model = load_model("update2_emotion_detection_model.h5")

model.compile(optimizer='adam',  # Or your original optimizer
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Continue training for 30 more epochs
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,  # Additional epochs
    batch_size=128,
    verbose=1
)

# Evaluate the updated model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Save the updated model
model.save("update3_emotion_detection_model.h5")

# Display some misclassified images
plt.figure(figsize=(15, 10))
for i, idx in enumerate(misclassified_indices[:9]):  # Show first 9 misclassified images
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx].reshape(48, 48), cmap="gray")
    plt.title(f"True: {emotion_mapping[y_true[idx]]}\nPred: {emotion_mapping[y_pred_classes[idx]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()

from tensorflow.keras.models import load_model

# Load the previously saved model
model = load_model("update3_emotion_detection_model.h5")

model.compile(optimizer='adam',  # Or your original optimizer
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Continue training for 50 more epochs
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,  # Additional epochs
    batch_size=128,
    verbose=1
)

# Evaluate the updated model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Save the updated model
model.save("update4_emotion_detection_model.h5")

# Display some misclassified images
plt.figure(figsize=(15, 10))
for i, idx in enumerate(misclassified_indices[:9]):  # Show first 9 misclassified images
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx].reshape(48, 48), cmap="gray")
    plt.title(f"True: {emotion_mapping[y_true[idx]]}\nPred: {emotion_mapping[y_pred_classes[idx]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()

from tensorflow.keras.models import load_model

# Load the previously saved model
model = load_model("update4_emotion_detection_model.h5")

model.compile(optimizer='adam',  # Or your original optimizer
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Continue training for 50 more epochs
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,  # Additional epochs
    batch_size=128,
    verbose=1
)

# Evaluate the updated model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Save the updated model
model.save("update5_emotion_detection_model.h5")

# Display some misclassified images
plt.figure(figsize=(15, 10))
for i, idx in enumerate(misclassified_indices[:9]):  # Show first 9 misclassified images
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx].reshape(48, 48), cmap="gray")
    plt.title(f"True: {emotion_mapping[y_true[idx]]}\nPred: {emotion_mapping[y_pred_classes[idx]]}")
    plt.axis("off")

plt.tight_layout()
plt.show()